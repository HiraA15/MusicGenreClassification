{
  "name": "Music Genre Classification",
  "tagline": "",
  "body": "# Abstract\r\n\r\nThe purpose of this project is to use neural network programming to develop \r\nan artificially intelligent program capable of classifying genre’s of music. The audio \r\nfile my analysis is performed on is the GTZAN audio file. The k-means, fast fourier \r\ntransform and MFCC algorithms are utilized. Output will be in the form of graphs and \r\nprecise categories determined.\r\n\r\n# Problem Description\r\n\r\nMusic can be found in every culture and corner of the world. It has been around for \r\nas long as mankind has been capable of making a tune. Music may be classified into \r\ngenre’s. What differentiates a genre are the amplitude and frequency, rhythm and form. \r\nI postulate that I will be able to determine the genre (musical category) of a song \r\nusing its amplitude and frequency.\r\n\r\n# Method\r\nK-Means (knn): the algorithm which will cluster data according to similarities. In this\r\nscenario, based on the amplitudes and known amplitudes of genres. I used this to generate \r\na k-means scatter plot which shows where genre’s fall.\r\n\r\nFast Fourier Transform (FFT): the algorithm computes the sinusoidal frequency and phase \r\nconcepts of a sequence. It essentially will compute a frequency that can be used in MFCC. \r\nThis was used to generate a spectrogram.\r\n\r\nMel Frequency Cepstral Coefficient (MFCC): the computation that can use the FFT \r\nto compute a linear cosine transform of a log power spectrum. In python scikits.talkbox \r\ncontains an implementation of MFC that I will directly use. I used this algorithm \r\nprimarily to generate a spectrogram.\r\n\r\nGTZAN dataset: The dataset is used as a training and testing set. It consists of 1000 audio \r\nfiles, containing 10 genres, that are represented by 100 tracks each 30 seconds long. All \r\ntracks are in .au format which are converted into .wav format.\r\n\r\n# Results\r\n1. Can K-Means clustering compute genres?\r\n\r\nYes, it can. In fact it does so accurately. What was first done was to calculate the Euclidian \r\ndistance between two n-dimensions. This differentiates categories. By calculating the k shortest \r\ndistance and storing it in a dictionary, I obtained indices needed to categorize the data. \r\nIn order to classify songs, the k closest song was chosen with it’s fold features and its index. \r\nThe genre was then decided on. If there was a tie between genres, the furthest point was deleted \r\nand recursion ensued. \r\n\r\nUsing my results, I produced a scatter plot to show where each genre lies. While metal and \r\nindie are clear outliers and easy to classify, the algorithm had a hard time differentiating \r\nbetween metal rock and punk rock. This was shown when I tested song13 and song17 from the \r\nGTZAN testing set.\r\n\r\n2. Can a neural network be more effective than a model using human computations?\r\n\t\r\nIt seems that the answer is no. Although using the Fast Fourier transform in conjunction \r\nwith the Mel Frequency Cepstrum Coefficient proved very useful. I had my program generate \r\nMFCC features from the GTZAN audio files and save them onto my disk speeding up performance. \r\nAfter, I trained and saved the model in order to satisfy my neural network. The stored model \r\nwas the only model used for testing since I didn’t change audio files.\r\n \t\r\nTraining the model took an enormous amount of time. It classified material except it did so \r\ndefectively sometimes. The model had a tendency to lump jazz and country on occasion. Further \r\ninvestigation showed that because there were similarities between the thresholds and the \r\nfrequencies, the training model would need more training data in order to differentiate the two. \r\nIn categorizing other genres the MFCC and FFT did perfect.\r\n\t\r\nI generated a series of graphs including a confusion matrix, spectrogram, and a receiver operating \r\ncharacteristic (ROC) curve to show the differences that genres have. A confusion matrix judges the \r\noverall performance of an algorithm. An ROC curve is used to illustrate the performance of a \r\nclassifier system while the threshold is varied. A spectrogram is a visual representation of frequencies.\r\n\r\n3. Which algorithm was most efficient?\r\n\r\nThe algorithm that was the most efficient was the K-Means algorithm. Not only did it run through \r\nthe computations fast, but the more data I fed into it the quicker it was in classifying test \r\nsongs. While the MFCC and FFT were more powerful they were by no means more efficient. It took \r\na few hours to train the model and classifying one song had to be compared to everything in the model.\r\n\r\nResults were varied according to classification difficulties. As mentioned before, the \r\nk-means had trouble with categorizing metal rock and punk rock. The MFCC had trouble with jazz \r\nand country. Because the genres have overlapping frequencies, and amplitudes, it might be that \r\na genre is not perfectly classifiable when thresholds overlap. The spectrogram and the ROC curve \r\ngraphs prove that threshold overlapping makes classifications challenging.\r\n\t\r\n# Conclusion\r\nMy strategy of using three different algorithms to determine a musical genre was a bit \r\noverwhelming. In essence, all three determine genres using different modes. While my neural network \r\nproved less adept than the k-means model, I intend to use a larger selection of audio files to \r\nimprove system accuracy. Future work will include more in depth research and a way to utilize \r\ndifferent python tools.\r\n\r\n# Sources\r\nLerch, Alexander. Audio Content Analysis. N.p., n.d. Web. 19 Sept. 2016. \r\nTzanetakis, George, Georg Essl, and Perry Cook. \"Analysis of Musical Audio Signals.\" Computational Auditory Scene Analysis (2011): n. pag. Web. 16 Oct. 2016. \r\nClark, Sam, Danny Park, and Adrien Guerard. \"Sentiment Classification Using Machine Learning Techniques.\" International Journal of Science and Research (IJSR) 5.4 (2012): 819-21. 9 May 2012. Web. 18 Oct. 2016. \r\n\"Sklearn.cluster.KMeans¶.\" Sklearn.cluster.KMeans — Scikit-learn 0.18.1 Documentation. N.p., n.d. Web. 4 Nov. 2016. \r\nLutter, Michael. \"Mel-Frequency Cepstral Coefficients.\" The Speech Recognition Wiki. N.p., 25 Nov. 2014. Web. 6 Dec. 2016. \r\n\"Discrete Fourier Transform (numpy.fft)¶.\" Discrete Fourier Transform (numpy.fft) — NumPy V1.11 Manual. N.p., n.d. Web. 27 Oct. 2016.\r\nIrealva. \"Irealva/music-genre-classifier.\" GitHub. GitHub, 19 Nov. 2014. Web. 12 Dec. 2016.\r\n\"Jazdev (Jasdev Singh).\" GitHub. GitHub, n.d. Web. 12 Dec. 2016. \r\nBabak0032. \"Babak0032/Learning-Music-genres-.\" GitHub. GitHub, 03 June 2014. Web. 12 Dec. 2016. ",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}