<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Music Genre Classification by HiraA15</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Music Genre Classification</h1>
        <p></p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/HiraA15/MusicGenreClassification" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/HiraA15/MusicGenreClassification/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/HiraA15/MusicGenreClassification/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h1>

<p>The purpose of this project is to use neural network programming to develop 
an artificially intelligent program capable of classifying genre’s of music. The audio 
file my analysis is performed on is the GTZAN audio file. The k-means, fast fourier 
transform and MFCC algorithms are utilized. Output will be in the form of graphs and 
precise categories determined.</p>

<h1>
<a id="problem-description" class="anchor" href="#problem-description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problem Description</h1>

<p>Music can be found in every culture and corner of the world. It has been around for 
as long as mankind has been capable of making a tune. Music may be classified into 
genre’s. What differentiates a genre are the amplitude and frequency, rhythm and form. 
I postulate that I will be able to determine the genre (musical category) of a song 
using its amplitude and frequency.</p>

<h1>
<a id="method" class="anchor" href="#method" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Method</h1>

<p>K-Means (knn): the algorithm which will cluster data according to similarities. In this
scenario, based on the amplitudes and known amplitudes of genres. I used this to generate 
a k-means scatter plot which shows where genre’s fall.</p>

<p>Fast Fourier Transform (FFT): the algorithm computes the sinusoidal frequency and phase 
concepts of a sequence. It essentially will compute a frequency that can be used in MFCC. 
This was used to generate a spectrogram.</p>

<p>Mel Frequency Cepstral Coefficient (MFCC): the computation that can use the FFT 
to compute a linear cosine transform of a log power spectrum. In python scikits.talkbox 
contains an implementation of MFC that I will directly use. I used this algorithm 
primarily to generate a spectrogram.</p>

<p>GTZAN dataset: The dataset is used as a training and testing set. It consists of 1000 audio 
files, containing 10 genres, that are represented by 100 tracks each 30 seconds long. All 
tracks are in .au format which are converted into .wav format.</p>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h1>

<ol>
<li>Can K-Means clustering compute genres?</li>
</ol>

<p>Yes, it can. In fact it does so accurately. What was first done was to calculate the Euclidian 
distance between two n-dimensions. This differentiates categories. By calculating the k shortest 
distance and storing it in a dictionary, I obtained indices needed to categorize the data. 
In order to classify songs, the k closest song was chosen with it’s fold features and its index. 
The genre was then decided on. If there was a tie between genres, the furthest point was deleted 
and recursion ensued. </p>

<p>Using my results, I produced a scatter plot to show where each genre lies. While metal and 
indie are clear outliers and easy to classify, the algorithm had a hard time differentiating 
between metal rock and punk rock. This was shown when I tested song13 and song17 from the 
GTZAN testing set.</p>

<ol>
<li>Can a neural network be more effective than a model using human computations?</li>
</ol>

<p>It seems that the answer is no. Although using the Fast Fourier transform in conjunction 
with the Mel Frequency Cepstrum Coefficient proved very useful. I had my program generate 
MFCC features from the GTZAN audio files and save them onto my disk speeding up performance. 
After, I trained and saved the model in order to satisfy my neural network. The stored model 
was the only model used for testing since I didn’t change audio files.</p>

<p>Training the model took an enormous amount of time. It classified material except it did so 
defectively sometimes. The model had a tendency to lump jazz and country on occasion. Further 
investigation showed that because there were similarities between the thresholds and the 
frequencies, the training model would need more training data in order to differentiate the two. 
In categorizing other genres the MFCC and FFT did perfect.</p>

<p>I generated a series of graphs including a confusion matrix, spectrogram, and a receiver operating 
characteristic (ROC) curve to show the differences that genres have. A confusion matrix judges the 
overall performance of an algorithm. An ROC curve is used to illustrate the performance of a 
classifier system while the threshold is varied. A spectrogram is a visual representation of frequencies.</p>

<ol>
<li>Which algorithm was most efficient?</li>
</ol>

<p>The algorithm that was the most efficient was the K-Means algorithm. Not only did it run through 
the computations fast, but the more data I fed into it the quicker it was in classifying test 
songs. While the MFCC and FFT were more powerful they were by no means more efficient. It took 
a few hours to train the model and classifying one song had to be compared to everything in the model.</p>

<p>Results were varied according to classification difficulties. As mentioned before, the 
k-means had trouble with categorizing metal rock and punk rock. The MFCC had trouble with jazz 
and country. Because the genres have overlapping frequencies, and amplitudes, it might be that 
a genre is not perfectly classifiable when thresholds overlap. The spectrogram and the ROC curve 
graphs prove that threshold overlapping makes classifications challenging.</p>

<h1>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusion</h1>

<p>My strategy of using three different algorithms to determine a musical genre was a bit 
overwhelming. In essence, all three determine genres using different modes. While my neural network 
proved less adept than the k-means model, I intend to use a larger selection of audio files to 
improve system accuracy. Future work will include more in depth research and a way to utilize 
different python tools.</p>

<h1>
<a id="sources" class="anchor" href="#sources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sources</h1>

<p>Lerch, Alexander. Audio Content Analysis. N.p., n.d. Web. 19 Sept. 2016. 
Tzanetakis, George, Georg Essl, and Perry Cook. "Analysis of Musical Audio Signals." Computational Auditory Scene Analysis (2011): n. pag. Web. 16 Oct. 2016. 
Clark, Sam, Danny Park, and Adrien Guerard. "Sentiment Classification Using Machine Learning Techniques." International Journal of Science and Research (IJSR) 5.4 (2012): 819-21. 9 May 2012. Web. 18 Oct. 2016. 
"Sklearn.cluster.KMeans¶." Sklearn.cluster.KMeans — Scikit-learn 0.18.1 Documentation. N.p., n.d. Web. 4 Nov. 2016. 
Lutter, Michael. "Mel-Frequency Cepstral Coefficients." The Speech Recognition Wiki. N.p., 25 Nov. 2014. Web. 6 Dec. 2016. 
"Discrete Fourier Transform (numpy.fft)¶." Discrete Fourier Transform (numpy.fft) — NumPy V1.11 Manual. N.p., n.d. Web. 27 Oct. 2016.
Irealva. "Irealva/music-genre-classifier." GitHub. GitHub, 19 Nov. 2014. Web. 12 Dec. 2016.
"Jazdev (Jasdev Singh)." GitHub. GitHub, n.d. Web. 12 Dec. 2016. 
Babak0032. "Babak0032/Learning-Music-genres-." GitHub. GitHub, 03 June 2014. Web. 12 Dec. 2016. </p>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/HiraA15">HiraA15</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
